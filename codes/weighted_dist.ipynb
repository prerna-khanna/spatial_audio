{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import sounddevice as sd\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the parameters\n",
    "\n",
    "# Number of microphones\n",
    "M = 3\n",
    "\n",
    "# Order of Ambisonics\n",
    "P = 4  \n",
    "\n",
    "triangle_side = 4.2\n",
    "\n",
    "# Constants for the attenuation function\n",
    "volume_threshold = 0.9\n",
    "volume_range = 0.9\n",
    "hoa_threshold = 0.9\n",
    "hoa_range = 1.3\n",
    "\n",
    "def attenuation_and_rebalancing(d_m, t_l=volume_threshold, t_k=hoa_range, s_k_0=1.0, s_k_p_neg=-1.0, s_l_neg=-1.0):\n",
    "    \"\"\"\n",
    "    Distance-dependent attenuation and component re-balancing function.\n",
    "\n",
    "    Parameters:\n",
    "    - d_m: distance to the m-th microphone\n",
    "    - t_l: attenuation threshold\n",
    "    - t_k: re-balancing threshold\n",
    "    - s_k_0: slope for the 0th order component\n",
    "    - s_k_p_neg: slope for higher-order components (p>0)\n",
    "    - s_l_neg: slope for overall gain\n",
    "\n",
    "    Returns:\n",
    "    - Attenuation coefficient for the given distance\n",
    "    \"\"\"\n",
    "    def l(d_m):\n",
    "        return np.where(d_m <= t_l, 0, s_l(d_m - t_l))\n",
    "\n",
    "    def k_p(d_m):\n",
    "        return np.where(d_m <= t_k, 0, s_k_p(d_m - t_k))\n",
    "\n",
    "    def s_l(delta_d):\n",
    "        # Adjust this function based on the specific behavior of s_l\n",
    "        # For example, you can use a linear function: return s_l_neg * delta_d\n",
    "        return s_l_neg * delta_d\n",
    "\n",
    "    def s_k_p(delta_d):\n",
    "        # Adjust this function based on the specific behavior of s_k_p\n",
    "        # For p=0, the slope is positive; for p>0, the slope is negative\n",
    "        return np.where(delta_d <= 0, s_k_0, s_k_p_neg * delta_d)\n",
    "\n",
    "    return 10 ** ((l(d_m) + k_p(d_m)) / 20.0)\n",
    "\n",
    "\n",
    "def compute_distance(interp_point, mic_number, triangle_side):\n",
    "    # Microphone positions in the equilateral triangle\n",
    "    mic_positions = np.zeros((3, 2))\n",
    "    \n",
    "    mic_positions[0, :] = [0, 0]\n",
    "    mic_positions[1, :] = [triangle_side, 0]\n",
    "    mic_positions[2, :] = [triangle_side / 2, (triangle_side * np.sqrt(3)) / 2]\n",
    "    \n",
    "    \n",
    "    # Euclidean distance between the interpolation point and the microphone\n",
    "    distance = np.linalg.norm(interp_point - mic_positions[mic_number, :])\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_6354/253236692.py:5: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, mic1_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/11_20/mic1.wav')\n",
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_6354/253236692.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _, mic2_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/11_20/mic2.wav')\n",
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_6354/253236692.py:7: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _, mic3_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/11_20/mic3.wav')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time delay between mic1 and mic2: 24.19179 seconds\n",
      "Time delay between mic1 and mic3: 30.12671 seconds\n",
      "Time delay between mic2 and mic3: 5.93433 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "fs, mic1_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/11_20/mic1.wav')\n",
    "_, mic2_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/11_20/mic2.wav')\n",
    "_, mic3_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/11_20/mic3.wav')\n",
    "\n",
    "# Generate a 16 kHz tone\n",
    "tone_freq = 16000\n",
    "tone_duration = 5  # seconds\n",
    "t = np.arange(0, tone_duration, 1/fs)\n",
    "sync_tone = np.sin(2 * np.pi * tone_freq * t)\n",
    "\n",
    "channel = 0\n",
    "\n",
    "mic1_signal = mic1_signal[:, channel].astype(float)\n",
    "mic2_signal = mic2_signal[:, channel].astype(float)\n",
    "mic3_signal = mic3_signal[:, channel].astype(float)\n",
    "\n",
    "\n",
    "min_length = min(len(mic1_signal), len(mic2_signal), len(mic3_signal))\n",
    "mic1_signal = mic1_signal[:min_length]\n",
    "mic2_signal = mic2_signal[:min_length]\n",
    "mic3_signal = mic3_signal[:min_length]\n",
    "\n",
    "# Perform the Fourier transform\n",
    "f_mic1 = np.fft.fft(mic1_signal)\n",
    "f_mic2 = np.fft.fft(mic2_signal)\n",
    "f_mic3 = np.fft.fft(mic3_signal)\n",
    "\n",
    "# Calculate cross-correlation in the frequency domain\n",
    "correlation12 = np.fft.ifft(f_mic1 * np.conj(f_mic2))\n",
    "correlation13 = np.fft.ifft(f_mic1 * np.conj(f_mic3))\n",
    "correlation23 = np.fft.ifft(f_mic2 * np.conj(f_mic3))\n",
    "\n",
    "# Find the lag with maximum correlation\n",
    "lag12 = np.argmax(np.abs(correlation12))\n",
    "lag13 = np.argmax(np.abs(correlation13))\n",
    "lag23 = np.argmax(np.abs(correlation23))\n",
    "\n",
    "# Calculate time delays\n",
    "delay12 = lag12 / fs\n",
    "delay13 = lag13 / fs\n",
    "delay23 = lag23 / fs\n",
    "\n",
    "print(f'Time delay between mic1 and mic2: {delay12:.5f} seconds')\n",
    "print(f'Time delay between mic1 and mic3: {delay13:.5f} seconds')\n",
    "print(f'Time delay between mic2 and mic3: {delay23:.5f} seconds')\n",
    "\n",
    "lag = np.array([lag13, lag23, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_6354/1698702362.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  max_samples = max([wavfile.read(path_to_files + file_name)[1].shape[0] for file_name in file_names])\n",
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_6354/1698702362.py:12: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, y = wavfile.read(path_to_files + file_names[m])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load your ambisonic signals y_m_p(n) from WAV files\n",
    "path_to_files = '/Users/prerna/Documents/spatial_audio/data/11_20/'\n",
    "file_names = ['mic1.wav', 'mic2.wav', 'mic3.wav']  # Adjust with your file names\n",
    "\n",
    "# Initialize an array to store ambisonic signals\n",
    "max_samples = max([wavfile.read(path_to_files + file_name)[1].shape[0] for file_name in file_names])\n",
    "y_m_p = np.zeros((M, P, max_samples))  # Initialize with the maximum number of samples\n",
    "\n",
    "\n",
    "for m in range(M):\n",
    "    # Read the WAV file\n",
    "    fs, y = wavfile.read(path_to_files + file_names[m])\n",
    "    \n",
    "    y = y[lag[m]: , :]\n",
    "    \n",
    "    # Take the 4 channels \n",
    "    y_m_p[m, :, :y.shape[0]] = y[:, :P].T\n",
    "\n",
    "# Step 3: Implement the interpolation algorithm\n",
    "\n",
    "# Number of samples\n",
    "N = y_m_p.shape[2]\n",
    "\n",
    "# Initialize the interpolated signal\n",
    "x_p = np.zeros(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation point coordinates\n",
    "# interp_point = np.array([triangle_side / 2, (triangle_side * np.sqrt(3)) / 6])  # centroid\n",
    "interp_point =  [1.05, (triangle_side * np.sqrt(3)) / 6]\n",
    "\n",
    "# Initialize an array to store the attenuation coefficients for each microphone\n",
    "a_p_values = np.zeros((M, N))\n",
    "\n",
    "# Compute the distance for all samples at once\n",
    "distances = np.array([compute_distance(interp_point, m, triangle_side) for m in range(M)])\n",
    "\n",
    "# Compute the attenuation coefficients for each microphone using broadcasting\n",
    "a_p_values = attenuation_and_rebalancing(distances[:, np.newaxis])\n",
    "\n",
    "# Update the interpolated signal using vectorized NumPy operations\n",
    "x_p = np.sum(a_p_values[:, :, np.newaxis] * y_m_p, axis=(0, 1))\n",
    "x_p = x_p/1000000000.0\n",
    "\n",
    "# Plot\n",
    "time_axis = np.arange(1, N + 1)\n",
    "wavfile.write('output_median1.wav', fs, x_p)\n",
    "plt.plot(time_axis, x_p)\n",
    "plt.title('Interpolated Signal')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_aud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
