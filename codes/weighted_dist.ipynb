{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import sounddevice as sd\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the parameters\n",
    "\n",
    "# Number of microphones\n",
    "M = 3\n",
    "\n",
    "# Order of Ambisonics\n",
    "P = 4  \n",
    "\n",
    "triangle_side = 6\n",
    "\n",
    "# Constants for the attenuation function\n",
    "volume_threshold = 0.9\n",
    "volume_range = 0.9\n",
    "hoa_threshold = 0.9\n",
    "hoa_range = 1.3\n",
    "\n",
    "# Define the attenuation coefficient function a_p(d_m)\n",
    "def l(d):\n",
    "    return volume_threshold * (1 - volume_range * d)\n",
    "\n",
    "def k_p(d):\n",
    "    return hoa_threshold * (1 - hoa_range * d)\n",
    "\n",
    "def a_p(d):\n",
    "    return 10 ** ((l(d) + k_p(d)) / 20)\n",
    "\n",
    "def compute_distance(interp_point, mic_number, triangle_side):\n",
    "    # Microphone positions in the equilateral triangle\n",
    "    mic_positions = np.zeros((3, 2))\n",
    "    \n",
    "    mic_positions[1, :] = [0, 0]\n",
    "    mic_positions[2, :] = [triangle_side, 0]\n",
    "    mic_positions[0, :] = [-triangle_side / 2, -(triangle_side * np.sqrt(3)) / 2]\n",
    "    \n",
    "    \n",
    "    # Euclidean distance between the interpolation point and the microphone\n",
    "    distance = np.linalg.norm(interp_point - mic_positions[mic_number, :])\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_69863/11191403.py:15: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _, mic1_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/mic1.wav')\n",
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_69863/11191403.py:16: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _, mic2_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/mic2.wav')\n",
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_69863/11191403.py:17: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  _, mic3_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/mic3.wav')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time delay between mic1 and mic2: 3.31844 seconds\n",
      "Time delay between mic1 and mic3: 6.36598 seconds\n",
      "Time delay between mic2 and mic3: 3.07129 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "fs, mic1_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/mic1.wav')\n",
    "_, mic2_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/mic2.wav')\n",
    "_, mic3_signal = wavfile.read('/Users/prerna/Documents/spatial_audio/data/mic3.wav')\n",
    "\n",
    "# Generate a 16 kHz tone\n",
    "tone_freq = 16000\n",
    "tone_duration = 5  # seconds\n",
    "t = np.arange(0, tone_duration, 1/fs)\n",
    "sync_tone = np.sin(2 * np.pi * tone_freq * t)\n",
    "\n",
    "channel = 0\n",
    "\n",
    "mic1_signal = mic1_signal[:, channel].astype(float)\n",
    "mic2_signal = mic2_signal[:, channel].astype(float)\n",
    "mic3_signal = mic3_signal[:, channel].astype(float)\n",
    "\n",
    "\n",
    "min_length = min(len(mic1_signal), len(mic2_signal), len(mic3_signal))\n",
    "mic1_signal = mic1_signal[:min_length]\n",
    "mic2_signal = mic2_signal[:min_length]\n",
    "mic3_signal = mic3_signal[:min_length]\n",
    "\n",
    "# Perform the Fourier transform\n",
    "f_mic1 = np.fft.fft(mic1_signal)\n",
    "f_mic2 = np.fft.fft(mic2_signal)\n",
    "f_mic3 = np.fft.fft(mic3_signal)\n",
    "\n",
    "# Calculate cross-correlation in the frequency domain\n",
    "correlation12 = np.fft.ifft(f_mic1 * np.conj(f_mic2))\n",
    "correlation13 = np.fft.ifft(f_mic1 * np.conj(f_mic3))\n",
    "correlation23 = np.fft.ifft(f_mic2 * np.conj(f_mic3))\n",
    "\n",
    "# Find the lag with maximum correlation\n",
    "lag12 = np.argmax(np.abs(correlation12))\n",
    "lag13 = np.argmax(np.abs(correlation13))\n",
    "lag23 = np.argmax(np.abs(correlation23))\n",
    "\n",
    "# Calculate time delays\n",
    "delay12 = lag12 / fs\n",
    "delay13 = lag13 / fs\n",
    "delay23 = lag23 / fs\n",
    "\n",
    "print(f'Time delay between mic1 and mic2: {delay12:.5f} seconds')\n",
    "print(f'Time delay between mic1 and mic3: {delay13:.5f} seconds')\n",
    "print(f'Time delay between mic2 and mic3: {delay23:.5f} seconds')\n",
    "\n",
    "lag = np.array([lag13, lag23, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_69863/2815712269.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  max_samples = max([wavfile.read(path_to_files + file_name)[1].shape[0] for file_name in file_names])\n",
      "/var/folders/fr/rdj3hsr55n349b9r69qgjmch0000gn/T/ipykernel_69863/2815712269.py:8: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, y = wavfile.read(path_to_files + file_names[m])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load your ambisonic signals y_m_p(n) from WAV files\n",
    "path_to_files = '/Users/prerna/Documents/spatial_audio/data/'\n",
    "file_names = ['mic1.wav', 'mic2.wav', 'mic3.wav']  # Adjust with your file names\n",
    "\n",
    "# Initialize an array to store ambisonic signals\n",
    "max_samples = max([wavfile.read(path_to_files + file_name)[1].shape[0] for file_name in file_names])\n",
    "y_m_p = np.zeros((M, P, max_samples))  # Initialize with the maximum number of samples\n",
    "\n",
    "\n",
    "for m in range(M):\n",
    "    # Read the WAV file\n",
    "    fs, y = wavfile.read(path_to_files + file_names[m])\n",
    "    \n",
    "    y = y[lag[m]: , :]\n",
    "    \n",
    "    # Take the 4 channels \n",
    "    y_m_p[m, :, :y.shape[0]] = y[:, :P].T\n",
    "\n",
    "# Step 3: Implement the interpolation algorithm\n",
    "\n",
    "# Number of samples\n",
    "N = y_m_p.shape[2]\n",
    "\n",
    "# Initialize the interpolated signal\n",
    "x_p = np.zeros(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation point coordinates\n",
    "# interp_point = np.array([triangle_side / 2, (triangle_side * np.sqrt(3)) / 6])  # centroid\n",
    "interp_point = [0,3]\n",
    "\n",
    "# Initialize an array to store the attenuation coefficients for each microphone\n",
    "a_p_values = np.zeros((M, N))\n",
    "\n",
    "# Compute the distance for all samples at once\n",
    "distances = np.array([compute_distance(interp_point, m, triangle_side) for m in range(M)])\n",
    "\n",
    "# Compute the attenuation coefficients for each microphone using broadcasting\n",
    "a_p_values = a_p(distances[:, np.newaxis])\n",
    "\n",
    "# Update the interpolated signal using vectorized NumPy operations\n",
    "x_p = np.sum(a_p_values[:, :, np.newaxis] * y_m_p, axis=(0, 1))\n",
    "x_p = x_p/1000000000.0\n",
    "\n",
    "# Plot\n",
    "time_axis = np.arange(1, N + 1)\n",
    "wavfile.write('output.wav', fs, x_p)\n",
    "plt.plot(time_axis, x_p)\n",
    "plt.title('Interpolated Signal')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_aud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
